# -*- coding: utf-8 -*-
"""Detection&Reconstruction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1whaxmeQIa-sYB8a1VBXscRGLQ2W_2toN
"""

!nvcc -V

import torch, torchvision
print(torch.__version__, torch.cuda.is_available())

!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/open-mmlab/mmdetection.git
# %cd mmdetection
!pip install -r requirements/build.txt
!pip install -v -e .

# Check Pytorch installation
import torch, torchvision
print(torch.__version__, torch.cuda.is_available())

# Check MMDetection installation
import mmdet
print(mmdet.__version__)

# Check mmcv installation
from mmcv.ops import get_compiling_cuda_version, get_compiler_version
print(get_compiling_cuda_version())
print(get_compiler_version())

!mkdir checkpoints
!wget -c https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r101_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r101_caffe_fpn_mstrain-poly_3x_coco_20210526_132339-3c33ce02.pth \
      -O checkpoints/mask_rcnn_r101_caffe_fpn_mstrain-poly_3x_coco_20210526_132339-3c33ce02.pth

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

!unzip /content/drive/MyDrive/SFPI.zip

!apt-get -q install tree
!tree SFPI

import mmcv
import matplotlib.pyplot as plt
img = mmcv.imread('SFPI/Images/train/floor_image_5074.tiff')
plt.figure(figsize=(15, 10))
plt.imshow(mmcv.bgr2rgb(img))
plt.show()

from mmcv import Config
from mmdet.apis import set_random_seed
import os.path as osp

classes = ('armchair', 'bed', 'door1', 'door2', 'sink1', 'sink2', 'sink3', 'sink4', 'sofa1', 'sofa2', 'table1', 'table2', 'table3', 'tub', 'window1', 'window2')

cfg = Config.fromfile('./configs/mask_rcnn/mask_rcnn_r101_caffe_fpn_mstrain-poly_3x_coco.py')
# Modify dataset type and path
cfg.dataset_type = 'SFPI'
cfg.classes = classes
cfg.data_root = './SFPI/'

cfg.data.test.ann_file = './SFPI/Annotations/test_annotation.json'
cfg.data.test.img_prefix = './SFPI/Images/val/'
cfg.data.test.classes = classes


cfg.data.train.ann_file = './SFPI/Annotations/train_annotation.json'
cfg.data.train.img_prefix = './SFPI/Images/train/'
cfg.data.train.classes = classes


cfg.data.val.ann_file = './SFPI/Annotations/val_annotation.json'
cfg.data.val.img_prefix = './SFPI/Images/val/'
cfg.data.val.classes = classes  

cfg.load_from = 'checkpoints/mask_rcnn_r101_caffe_fpn_mstrain-poly_3x_coco_20210526_132339-3c33ce02.pth'
# Set up working dir to save files and logs.
cfg.work_dir = './tutorial_exps'
cfg.optimizer.lr = 0.02 / 8
cfg.lr_config.warmup = None
cfg.log_config.interval = 10

# We can set the evaluation interval to reduce the evaluation times
cfg.evaluation.interval = 12
# We can set the checkpoint saving interval to reduce the storage cost
cfg.checkpoint_config.interval = 12

# Set seed thus the results are more reproducible
cfg.seed = 0
set_random_seed(0, deterministic=False)
cfg.gpu_ids = range(1)
cfg.log_config.hooks = [
    dict(type='TextLoggerHook'),
    dict(type='TensorboardLoggerHook')]

print(f'Config:\n{cfg.pretty_text}')

from mmdet.datasets import build_dataset
from mmdet.models import build_detector
from mmdet.apis import train_detector


# Build dataset
datasets = [build_dataset(cfg.data.train)]

# Build the detector
model = build_detector(
    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))
# Add an attribute for visualization convenience
model.CLASSES = datasets[0].CLASSES

# Create work_dir
mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))
train_detector(model, datasets, cfg, distributed=False, validate=True)

# Commented out IPython magic to ensure Python compatibility.
# load tensorboard in colab
# %load_ext tensorboard

# see curves in tensorboard
# %tensorboard --logdir ./tutorial_exps

from mmdet.apis import init_detector, inference_detector, show_result_pyplot
from mmdet.models import build_detector
img = mmcv.imread('SFPI/Images/train/floor_image_5074.tiff')

model.cfg = cfg
result = inference_detector(model, img)
show_result_pyplot(model, img, result)

!git clone https://github.com/zcemycl/TF2DeepFloorplan.git
!pip install gdown
!pip install --upgrade --no-cache-dir gdown
!gdown https://drive.google.com/uc?id=1czUSFvk6Z49H-zRikTc67g2HUUz4imON
!unzip log.zip
!rm log.zip

import tensorflow as tf
import sys
sys.path.append('./TF2DeepFloorplan/')
from net import *
from data import *
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
from argparse import Namespace
import os
import gc
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
sys.path.append('./TF2DeepFloorplan/utils/')
from rgb_ind_convertor import *
from util import *
from legend import *
from deploy import *
print(tf.test.is_gpu_available())

inp = mpimg.imread('./SFPI/Images/train/floor_image_1870.tiff')

args = Namespace(image='./SFPI/Images/train/floor_image_1870.tiff',
        weight='./log/store/G',loadmethod='log',
        postprocess=True,colorize=True,
        save=None)
result = main(args)

plt.imshow(inp); plt.xticks([]); plt.yticks([]);

model,img,shp = init(args)
logits_cw,logits_r = predict(model,img,shp)

logits_cw = tf.image.resize(logits_cw,shp[:2])
cw = convert_one_hot_to_image(logits_cw)[0].numpy()
plt.imshow(cw.squeeze()); plt.xticks([]); plt.yticks([]);

r_color,cw_color = colorize(r.squeeze(),cw.squeeze())
plt.imshow(cw_color); plt.xticks([]); plt.yticks([]);